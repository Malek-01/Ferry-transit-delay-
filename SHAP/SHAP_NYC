# Import necessary libraries
from sklearn.ensemble import GradientBoostingRegressor
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import r2_score
import shap
import matplotlib.pyplot as plt

# Load the merged data
data = pd.read_csv("Data-NYC.csv")

# Define features and target
X = data.iloc[:, np.r_[0, 1, 3, 4, 5, 6, 7, 10, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29]]
y = data.iloc[:, 8]

# Encode non-numeric columns
label_encoder = LabelEncoder()
non_numeric_columns = X.select_dtypes(exclude=['int', 'float']).columns
X[non_numeric_columns] = X[non_numeric_columns].apply(lambda col: label_encoder.fit_transform(col))

# Impute missing values
imputer = SimpleImputer(strategy='mean')
X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

# Split data into training and testing sets
train_pct_index = int(0.8 * len(data))
X_train, X_test = X.iloc[:train_pct_index], X.iloc[train_pct_index:]
y_train, y_test = y.iloc[:train_pct_index], y.iloc[train_pct_index:]

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Convert scaled arrays back to DataFrame to keep column names
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)

# Train the model
reg = GradientBoostingRegressor()
reg.fit(X_train_scaled_df, y_train)

# Make predictions
y_pred = reg.predict(X_test_scaled_df)

# Explain predictions using SHAP
explainer = shap.Explainer(reg)
shap_values = explainer(X_test_scaled_df)

# Evaluate the model
print('R^2 Score:', r2_score(y_test, y_pred))
print(f"Shap values length: {len(shap_values)}\n")
print(f"Sample shap value:\n{shap_values[0]}")

# Visualize SHAP values as a bar plot
shap.summary_plot(shap_values, X_test_scaled_df, plot_type='bar')
plt.savefig('/mnt/data/Shap1_NYC.png')
